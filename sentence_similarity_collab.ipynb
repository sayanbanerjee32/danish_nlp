{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "sentence_similarity.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayanbanerjee32/danish_nlp/blob/main/sentence_similarity_collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SysYG9RiBA32"
      },
      "source": [
        "# Danish Sentence similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEO5qpcxBA4U"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yBp73D8BA4V"
      },
      "source": [
        "# import os\n",
        "# os.chdir('D:/DataScienceWorkSpace/danish_sentence_similarty/src')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x5EkZY2BA4W"
      },
      "source": [
        "# data fie path in local\n",
        "data_file = 'https://raw.githubusercontent.com/lassehjorthmadsen/data-science-assignment/master/data/sentences.csv'\n",
        "#'../data/sentences.csv'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eE-fQPOmBA4W",
        "outputId": "0628e166-8065-4efa-f132-48f61b5c6e5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# read the sentences in a dataframe\n",
        "sentence_df = pd.read_csv(data_file)\n",
        "sentence_df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10-12-176</td>\n",
              "      <td>Vanddamp er en usynlig gas, der forekommer i s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10-13-182</td>\n",
              "      <td>Er der nogen herinde der har erfaring med at k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10-14-29</td>\n",
              "      <td>Ved ikke lige hvordan disse er i størrelsen?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10-16-39</td>\n",
              "      <td>Dog kan jeg godt lide pang farver;)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10-17-297</td>\n",
              "      <td>Pengene bliver dog ofte først udbetalt efter 5...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                               text\n",
              "0  10-12-176  Vanddamp er en usynlig gas, der forekommer i s...\n",
              "1  10-13-182  Er der nogen herinde der har erfaring med at k...\n",
              "2   10-14-29       Ved ikke lige hvordan disse er i størrelsen?\n",
              "3   10-16-39                Dog kan jeg godt lide pang farver;)\n",
              "4  10-17-297  Pengene bliver dog ofte først udbetalt efter 5..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyBr6QlnBA4X",
        "outputId": "75b1c4ce-fb85-4767-e2f2-e8774dde67fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# target sentence for finding similar senences\n",
        "target_sentence = sentence_df.loc[sentence_df['id']=='7-21-440','text']\n",
        "target_sentence.values[0]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ifølge Dansk Kennelklub angriber muskelhunde dyr og mennesker cirka hver 14. dag.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGe9Rt8JBA4Y"
      },
      "source": [
        "English translation for this sentence - __According to the Danish Kennel Club, muscular dogs attack animals and humans approximately every 14 days.__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY11MG2dBA4Y"
      },
      "source": [
        "## Option 1: Toenization > cleaning > Count vectorizer / TF-IDF vectorizer > Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM8wwm3uBA4Z",
        "outputId": "4d85d63a-6729-418e-9250-08470443a618"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.stem.snowball import DanishStemmer\n",
        "\n",
        "\n",
        "from cleantext import clean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQId98B1BA4Z",
        "outputId": "43fd9650-1389-4d1b-ffc2-3c597362d028"
      },
      "source": [
        "# tokenization function with Danish language Stemmer\n",
        "def tokenize(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    stems = []\n",
        "    for item in tokens:\n",
        "        stems.append(DanishStemmer().stem(item))\n",
        "    return stems\n",
        "\n",
        "# clean text by lowering abd removing email, number, url, currency, punctuation, \n",
        "def normalize_text(text):\n",
        "    return clean(text,\n",
        "     no_urls=True,                  # replace all URLs with a special token\n",
        "    no_emails=True,                # replace all email addresses with a special token\n",
        "    no_phone_numbers=True,         # replace all phone numbers with a special token\n",
        "    no_numbers=True,               # replace all numbers with a special token\n",
        "    no_digits=True,                # replace all digits with a special token\n",
        "    no_currency_symbols=True,      # replace all currency symbols with a special token\n",
        "    no_punct=True,\n",
        "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
        "    replace_with_url=\"\",\n",
        "    replace_with_email=\"\",\n",
        "    replace_with_phone_number=\"\",\n",
        "    replace_with_number=\"\",\n",
        "    replace_with_currency_symbol=\"\",\n",
        "#     replace_with_punct=\" ~PUNCT~ \",          # instead of removing punctuations you may replace them\n",
        "#     replace_with_url=\" ~URL~ \",\n",
        "#     replace_with_email=\" ~EMAIL~ \",\n",
        "#     replace_with_phone_number=\" ~PHONE~ \",\n",
        "#     replace_with_number=\" ~NUMBER~ \",\n",
        "#     replace_with_currency_symbol=\" ~CUR~ \",\n",
        "    lang=\"de\") # german is used as assumed that german would be closeer to Danish that english\n",
        "\n",
        "# sample output for the target text\n",
        "tokenize(normalize_text(target_sentence.values[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['iflg',\n",
              " 'dansk',\n",
              " 'kennelklub',\n",
              " 'angrib',\n",
              " 'muskelhund',\n",
              " 'dyr',\n",
              " 'og',\n",
              " 'mennesk',\n",
              " 'cirka',\n",
              " 'hver',\n",
              " 'dag']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbAAB00uBA4a",
        "outputId": "d5c49f36-e478-4efc-abd4-d4db22f8a6bb"
      },
      "source": [
        "# create a replica of the sentence dataframe for processing\n",
        "sentence_df_cp_op1 = sentence_df.copy()\n",
        "sentence_df_cp_op1 = sentence_df_cp_op1.text.apply(normalize_text)\n",
        "sentence_df_cp_op1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       vanddamp er en usynlig gas der forekommer i st...\n",
              "1       er der nogen herinde der har erfaring med at k...\n",
              "2              ved ikke lige hvordan disse er i strrelsen\n",
              "3                       dog kan jeg godt lide pang farver\n",
              "4       pengene bliver dog ofte frst udbetalt efter da...\n",
              "                              ...                        \n",
              "4995    i dag i idrt skulle vi sa have bip test hvor j...\n",
              "4996    p men tnkt nu hvis de bragte mere fra danskspr...\n",
              "4997                             kathani hejsa allesammen\n",
              "4998    weeeeeee jeg har mega optur pa de var begge mi...\n",
              "4999    archon der blev jo ikke sagt noget om hvem der...\n",
              "Name: text, Length: 5000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkFJg4kaBA4b"
      },
      "source": [
        "### Cosine similarity on count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vz9dCbIBA4b",
        "outputId": "de828b81-4ca4-4b34-a1b5-8cdb800c60a9"
      },
      "source": [
        "# fit count vectorizer with Danish stop words\n",
        "# use the custom tokenizer with Danish Stemmer\n",
        "count_vect = CountVectorizer(tokenizer=tokenize, stop_words=stopwords.words('danish'))\n",
        "# fit on cleaned text\n",
        "count_vect_matrix = count_vect.fit_transform(sentence_df_cp_op1)\n",
        "# vocab sze 13574\n",
        "count_vect_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 13574)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paR8bIPhBA4c"
      },
      "source": [
        "# find cosine similarity for the count vector matrix\n",
        "cosine_matrix_cv = cosine_similarity(count_vect_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWL5GTs5BA4c"
      },
      "source": [
        "# convert to Data Frame\n",
        "cosine_df_cv = pd.DataFrame(cosine_matrix_cv, columns = sentence_df['id'], index = sentence_df['id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-BEQFABA4c",
        "outputId": "48d471fd-119c-4c1b-c2d9-4acaa41711c6"
      },
      "source": [
        "# select the row for target sentence\n",
        "target_cosine_array = cosine_df_cv.loc['7-21-440',:]\n",
        "# sort descending\n",
        "target_cosine_array.sort_values(ascending = False)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "7-21-440      1.000000\n",
              "47-2-28       0.316228\n",
              "51-33-2622    0.258199\n",
              "36-0-1231     0.239046\n",
              "42-26-238     0.239046\n",
              "6-37-308      0.223607\n",
              "45-86-368     0.223607\n",
              "38-8-2425     0.223607\n",
              "51-89-2877    0.223607\n",
              "20-10-28      0.223607\n",
              "Name: 7-21-440, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwWdFZZrBA4d"
      },
      "source": [
        "# gather indices for top 10 similar sentences\n",
        "top_10_similarity = target_cosine_array.sort_values(ascending = False)[:10].index.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKZJY0dbBA4d",
        "outputId": "35416994-cda2-42d3-aa1a-b7daf9c1d2b8"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[1],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I dag'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGY6rWLuBA4e",
        "outputId": "90570a13-6747-424f-cd3e-71760c820d07"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[2],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hver dag i december op til juleaften sendes et afsnit.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFNa9TNNBA4e",
        "outputId": "6a7616a0-0f38-49b6-edb5-882d603ce875"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[3],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Det er der min arbejdsinteresse ligger, og det er noget, som jeg kan bruge hver dag.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7OL-OeHBA4e",
        "outputId": "6d225d3e-ddd5-439a-e153-047d1edc8cd8"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[4],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Danskerne er blandt de europæere, som hver for sig producerer mest affald.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa-7A0Q9BA4f",
        "outputId": "e925385e-3fcd-49ef-889c-bd85b1d0d3ba"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[5],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hovedårsagen til, at Katrina blev så dyr, at skaderne blev så omfangsrige, er ganske enkelt, at der i dag bor langt flere mennesker i kystområderne end tidligere.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWd3V9NpBA4f"
      },
      "source": [
        "### Cosine similarity on TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJtrTtX4BA4f",
        "outputId": "7ba772c1-9205-4cb0-8a0d-bf1d3d770268"
      },
      "source": [
        "# fit tf-idf vectorizer with Danish stop words\n",
        "# use the custom tokenizer with Danish Stemmer\n",
        "tfidf_vect = TfidfVectorizer(tokenizer=tokenize, stop_words=stopwords.words('danish'))\n",
        "# fit on cleaned text\n",
        "tfidf_vect_matrix = tfidf_vect.fit_transform(sentence_df_cp_op1)\n",
        "tfidf_vect_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\danish_nlp\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['all', 'and', 'bliv', 'dis', 'eft', 'ell', 'hav', 'havd', 'hend', 'ikk', 'kun', 'mang', 'meg', 'nog', 'nogl', 'skul', 'und', 'vær'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 13574)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kI114NJBA4g"
      },
      "source": [
        "# pairwise cosine similarity for tf-idf vector matrix\n",
        "cosine_matrix_ti = cosine_similarity(tfidf_vect_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNmyVxtfBA4i"
      },
      "source": [
        "# convert to DF\n",
        "cosine_df_ti = pd.DataFrame(cosine_matrix_ti, columns = sentence_df['id'], index = sentence_df['id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xzUG-CQBA4j",
        "outputId": "6efe8a83-8ad6-43a6-c191-0efef2b784a1"
      },
      "source": [
        "# select row for target sentence\n",
        "target_cosine_array = cosine_df_ti.loc['7-21-440',:]\n",
        "# sort descending\n",
        "target_cosine_array.sort_values(ascending = False)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "7-21-440      1.000000\n",
              "47-2-28       0.216134\n",
              "38-20-1059    0.180219\n",
              "45-86-368     0.179803\n",
              "36-0-1231     0.174177\n",
              "38-78-1469    0.167071\n",
              "34-2-723      0.166653\n",
              "6-37-308      0.166108\n",
              "40-81-2158    0.154190\n",
              "51-33-2622    0.152718\n",
              "Name: 7-21-440, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Rrsh0DBA4j"
      },
      "source": [
        "# Indices for top 10 similr sentences\n",
        "top_10_similarity = target_cosine_array.sort_values(ascending = False)[:10].index.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yS0zRgBBA4j",
        "outputId": "1cb7ac7a-7f1f-4d8b-f2d9-636cc0d08992"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[1],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I dag'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toXHMiRhBA4k",
        "outputId": "27d70c87-78d6-4220-910d-92b9ff9dd652"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[2],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Jeg ved, at niveauet er højt blandt alle angriberne i Serie A og kræver en toppræstation hver eneste gang.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYvvzkXLBA4l",
        "outputId": "d4d85fb5-904d-4edd-a00e-04bfdd8c05b2"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[3],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hvad er dyrets yndlingsfoder?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaYOzsNWBA4l",
        "outputId": "b61c4321-11b8-4b50-8166-8d011abab286"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[4],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Det er der min arbejdsinteresse ligger, og det er noget, som jeg kan bruge hver dag.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIWROOGkBA4m",
        "outputId": "441d7ab6-1b79-408d-ace8-2950032e72c7"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[5],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Men det fik ikke den farlige angriber til at skåne City.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysev0_7BBA4n"
      },
      "source": [
        "## Option 2: spaCy word embedding vector for sentence similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StexwZIxBA4n"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a33Q9tO1BA4n"
      },
      "source": [
        "# load a spaCy model, depending on language, scale, etc.\n",
        "nlp = spacy.load(\"da_core_news_md\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rc_GSf1BA4o",
        "outputId": "e5352762-d8eb-4cd1-d18a-fce4be1b0dcb"
      },
      "source": [
        "# create replica for cleaned text df from last section\n",
        "sentence_df_cp_op2 = sentence_df_cp_op1.copy()\n",
        "sentence_df_cp_op2 = pd.DataFrame(sentence_df_cp_op2.values, columns = ['text'], index = sentence_df['id'])\n",
        "sentence_df_cp_op2.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10-12-176</th>\n",
              "      <td>vanddamp er en usynlig gas der forekommer i st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10-13-182</th>\n",
              "      <td>er der nogen herinde der har erfaring med at k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10-14-29</th>\n",
              "      <td>ved ikke lige hvordan disse er i strrelsen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10-16-39</th>\n",
              "      <td>dog kan jeg godt lide pang farver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10-17-297</th>\n",
              "      <td>pengene bliver dog ofte frst udbetalt efter da...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        text\n",
              "id                                                          \n",
              "10-12-176  vanddamp er en usynlig gas der forekommer i st...\n",
              "10-13-182  er der nogen herinde der har erfaring med at k...\n",
              "10-14-29          ved ikke lige hvordan disse er i strrelsen\n",
              "10-16-39                   dog kan jeg godt lide pang farver\n",
              "10-17-297  pengene bliver dog ofte frst udbetalt efter da..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_ShmAA9BA4o"
      },
      "source": [
        "# nlp pipeline for target sentence\n",
        "base = nlp(sentence_df_cp_op2.loc['7-21-440',:].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqBE338WBA4p"
      },
      "source": [
        "# custom function for similarity scoring between 2 sentences\n",
        "def calculate_similarity(text2):\n",
        "    compare = nlp(text2)\n",
        "    return base.similarity(compare)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRUP3q9QBA4q",
        "outputId": "683526ec-2970-4702-b530-7201d3c2533c"
      },
      "source": [
        "# apply on each row\n",
        "sentence_df_cp_op2['sim_score'] = sentence_df_cp_op2['text'].apply(calculate_similarity)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D:\\Anaconda\\envs\\danish_nlp\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8PbIuCXBA4q"
      },
      "source": [
        "# sort descending\n",
        "sentence_df_cp_op2.sort_values(by = ['sim_score'], ascending = False, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucsOu4pmBA4r"
      },
      "source": [
        "# top 10 similar sentences, index 0 being the sentence itself\n",
        "top_10 = sentence_df_cp_op2.iloc[:10,:]['text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG2sXooBBA4r",
        "outputId": "8e5a2b71-7a36-47d5-f5f9-3704348a49e5"
      },
      "source": [
        "top_10[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nar man kommer slbende med vrkende kn og ildrd nse efter timers vandring gr det godt at stte sig til bordet sammen med de andre gster og bliver krset for i en fransk bjerghytte'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZqE-yMCBA4s",
        "outputId": "03c23db9-b677-4383-c026-ed877226fdf9"
      },
      "source": [
        "top_10[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'stadig flere danskere fatter interesse for den kontante sportsgren hvor veltrnede mnd pa langt over kilo kaster sig efter hinanden'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbtNlMXYBA4s",
        "outputId": "2fd33028-3e46-4bce-e1af-c997043f6687"
      },
      "source": [
        "top_10[3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'det tager i hvert fald en hel dag at overvre indmarchen af de snorlige rkker af musketerer farverige flagkastere grnne skytter krigere med armbrster byens skyttedronning og de forskellige madvogne som helt bogstaveligt smider brd og plser i hovedet pa publikum'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX_cFgBgBA4t",
        "outputId": "b25eac5e-4256-47fa-b434-4541ae727951"
      },
      "source": [
        "top_10[4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'og nok stter to unge mnd sig pa fortovscafeen og far en kop kaffe og taler arabisk men det er cafe latte de taler ogsa dansk og de har parkeret en stor kassevogn foran cafeen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LgxUdRMBA4t",
        "outputId": "ca627d81-4823-496a-9847-98e79cddc037"
      },
      "source": [
        "top_10[5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hver lrdag klokken mdes en gruppe kinesiske forldre og deres brn i little mermaid chinese culture school der startede som et privat initiativ i mens forldrene sludrer og dyrker tai chi far brnene undervisning i kinesisk sprog og kultur i de lante klasselokaler'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5AoVaCJBA4u"
      },
      "source": [
        "## Option 3: BERT embedding for Danish > Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EYsrBA5BA4u"
      },
      "source": [
        "# BERT based sentence embedding for Danish\n",
        "from danish_bert_embeddings import DanishBertEmbeddings\n",
        "embedder = DanishBertEmbeddings()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQpG4CPeBA4u"
      },
      "source": [
        "# sample embedding\n",
        "embedding = embedder.embed(target_sentence.values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ve3WJgBBA4v",
        "outputId": "826cf76b-e5a5-4c5c-efb2-de49a8a9239a"
      },
      "source": [
        "embedding.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clmi4KzVBA4v"
      },
      "source": [
        "# convert to embedding for each sentence\n",
        "sentence_df_embed = sentence_df['text'].apply(embedder.embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCqVw4UoBA4v"
      },
      "source": [
        "# convert to np array\n",
        "sentence_embed_list = [t.numpy() for t in sentence_df_embed]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCraL9YdBA4w"
      },
      "source": [
        "### Cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9n7SZYpBA4w"
      },
      "source": [
        "# pairewwise cosine similarity between sentence embeddings\n",
        "cosine_matrix = cosine_similarity(sentence_embed_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ik6b5hdBA4w"
      },
      "source": [
        "# convert to dataframe\n",
        "cosine_df = pd.DataFrame(cosine_matrix, columns = sentence_df['id'], index = sentence_df['id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5v3FuShBA4x",
        "outputId": "b5638a00-b44c-4c58-c595-4b6b6a0d2ce0"
      },
      "source": [
        "# select the row for target sentence\n",
        "target_cosine_array = cosine_df.loc['7-21-440',:]\n",
        "# sort descending\n",
        "target_cosine_array.sort_values(ascending = False)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "7-21-440      1.000000\n",
              "38-21-615     0.713109\n",
              "36-0-2615     0.705893\n",
              "6-37-308      0.705858\n",
              "51-3-3235     0.699858\n",
              "36-7-877      0.694900\n",
              "40-44-510     0.693219\n",
              "3-28-67       0.692790\n",
              "38-59-1673    0.692642\n",
              "51-34-3098    0.692097\n",
              "Name: 7-21-440, dtype: float32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw0DE2s7BA4x"
      },
      "source": [
        "# gather indices for top 10 similr sentences\n",
        "top_10_similarity = target_cosine_array.sort_values(ascending = False)[:10].index.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XagZkf4yBA4x",
        "outputId": "1caed1af-f889-4b3b-dfe6-27baae1e1f6e"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[1],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Han er fossilekspert, og foruden at være museumsinspektør ved Geomuseum Faxe er han forsker ved Københavns Universitet:\" Over revet var der 200- 400 meter havvand, og Thoracosaurus har- akkurat som nulevende havkrokodiller- jagtet sit bytte i de øvre vandlag.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuB6F9mlBA4y",
        "outputId": "cfb6ee98-1f71-4e22-9525-95e2dd7ad1a5"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[2],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'På 24 timer mellem 15. og 16. april 1949 fløj 1. 398 maskiner i alt 12. 849 tons fragt ind til den isolerede storby'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtWb2gYPBA4y",
        "outputId": "8f27b199-10cb-4963-be1c-be48048ad4b1"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[3],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hovedårsagen til, at Katrina blev så dyr, at skaderne blev så omfangsrige, er ganske enkelt, at der i dag bor langt flere mennesker i kystområderne end tidligere.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faRTVbmwBA4y",
        "outputId": "36ddd70d-d879-4981-988f-1847ff4c349e"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[4],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Men indtil nu er alle teorierne kommet mere eller mindre til kort, da man hele tiden kan finde dyr, der har noget, der ligner menneskelige egenskaber.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJe-IvnbBA4z",
        "outputId": "5fcaf871-9f03-4551-ff66-beaf77d2687d"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[5],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Børshandlere er såvidt vides udstyret med samme biologiske profil som alle andre mennesker.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-GmyRDfBA4z"
      },
      "source": [
        "## Option 4: Sub word tokenization > TF-IDF vercorization > cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3e3N2EWBA40"
      },
      "source": [
        "import sentencepiece as spm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ybu5_e4BA40"
      },
      "source": [
        "# file for subword tokenization training\n",
        "sub_word_file = '../data/sub_word_training.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJHdOnLnBA40"
      },
      "source": [
        "all_sentences = '\\n'.join(sentence_df['text'])\n",
        "with open(sub_word_file, 'w') as _file:\n",
        "    _file.write(all_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y74c8_kuBA40"
      },
      "source": [
        "# train sentencepiece model from sub_word_file and makes `m.model` and `m.vocab`\n",
        "# `m.vocab` is just a reference. not used in the segmentation.\n",
        "spm.SentencePieceTrainer.train('--input=../data/sub_word_training.txt --model_prefix=m --vocab_size=10000')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIhRMbUEBA41",
        "outputId": "35c0951d-f8c3-40ab-ac09-ef141c04b5fc"
      },
      "source": [
        "# makes segmenter instance and loads the model file (m.model)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('m.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmGUkviuBA41",
        "outputId": "001b0a35-4a85-45d0-9ba6-29e4f7fccf3f"
      },
      "source": [
        "# encode: text => id\n",
        "print(sp.encode_as_pieces(target_sentence.values[0]))\n",
        "print(sp.encode_as_ids(target_sentence.values[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁If', 'ø', 'lge', '▁Dansk', '▁Kenne', 'l', 'klub', '▁angriber', '▁mu', 'skel', 'hund', 'e', '▁dyr', '▁og', '▁mennesker', '▁cirk', 'a', '▁hver', '▁14', '.', '▁dag', '.']\n",
            "[930, 0, 184, 363, 2899, 59, 3358, 3042, 4114, 8993, 4280, 16, 1092, 6, 335, 1428, 86, 190, 527, 5, 155, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEOKPzJPBA44"
      },
      "source": [
        "### Cosine similarity on TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hjoy86HLBA44",
        "outputId": "71c12bdf-0f57-4a45-eb67-c3f22c17dd96"
      },
      "source": [
        "# create a replica of the sentence dataframe for processing\n",
        "sentence_df_cp_op4 = sentence_df.copy()\n",
        "sentence_df_cp_op4.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3p-B5rDBA44",
        "outputId": "781ecfe6-96b9-4bbd-9479-36d906cf3efd"
      },
      "source": [
        "# fit count vectorizer with Danish stop words\n",
        "# use the custom tokenizer with Danish Stemmer\n",
        "tfidf_vect_sw = TfidfVectorizer(tokenizer=sp.encode_as_ids)#, stop_words=stopwords.words('danish'))\n",
        "# fit on cleaned text\n",
        "tfidf_vect_matrix_sw = tfidf_vect_sw.fit_transform(sentence_df_cp_op4.text)\n",
        "# vocab sze 13574\n",
        "tfidf_vect_matrix_sw.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 8095)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd9Fuq9PBA45"
      },
      "source": [
        "# find cosine similarity for the count vector matrix\n",
        "cosine_matrix_ti_sw = cosine_similarity(tfidf_vect_matrix_sw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEa1v8GhBA45"
      },
      "source": [
        "# convert to Data Frame\n",
        "cosine_df_ti_sw = pd.DataFrame(cosine_matrix_ti_sw, columns = sentence_df['id'], index = sentence_df['id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTu4pUcTBA45",
        "outputId": "af588cc9-dd9b-452c-c7d3-5fc18097314a"
      },
      "source": [
        "# select the row for target sentence\n",
        "target_cosine_array = cosine_df_ti_sw.loc['7-21-440',:]\n",
        "# sort descending\n",
        "target_cosine_array.sort_values(ascending = False)[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "7-21-440      1.000000\n",
              "34-7-768      0.186515\n",
              "47-2-28       0.175104\n",
              "40-81-2158    0.170774\n",
              "38-78-1469    0.169889\n",
              "34-60-944     0.167158\n",
              "38-20-1059    0.163503\n",
              "51-33-1121    0.163082\n",
              "6-37-308      0.154364\n",
              "36-90-2811    0.149406\n",
              "Name: 7-21-440, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dXS-9RABA46"
      },
      "source": [
        "# gather indices for top 10 similar sentences\n",
        "top_10_similarity = target_cosine_array.sort_values(ascending = False)[:10].index.tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwiKSc4nBA46",
        "outputId": "fcee0e6c-306c-44ef-85ba-a3770efd7056"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[1],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hvor forbrugernes valgmuligheder for 20 år siden kunne tælles på en hånd eller to, så kan de i dag vælge mellem cirka 150 forskellige realkreditlån.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F378EHiDBA47",
        "outputId": "7e1f1287-8fa5-4d47-c9bf-dd286d2528a9"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[2],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I dag'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvXMBlygBA47",
        "outputId": "5787e50e-e8ad-4f09-a6d0-b35de852ac7c"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[3],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ifølge Henning Otte Hansen må forbrugerne herhjemme nu nok under alle omstændigheder affinde sig med, at maden er relativt dyr:'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5BwixmWBA47",
        "outputId": "f7a31fe7-de16-442f-c8b9-7e5fff56edb1"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[4],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Men det fik ikke den farlige angriber til at skåne City.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6bkY1GVBA48",
        "outputId": "bd877b8f-f786-482d-b946-df21ad5030ab"
      },
      "source": [
        "sentence_df.loc[sentence_df.id == top_10_similarity[5],'text'].values[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ifølge kilderne er brødrene rejst udenlands.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w903pDxwBA48"
      },
      "source": [
        "## Option 5: Sub word tokenization > TOP2VEC for topic clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EykHj396B8fe",
        "outputId": "6e18d7f6-d092-4657-c4d4-95e963e7a06b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#!pip install top2vec[sentence_encoders]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting top2vec[sentence_encoders]\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/b0/7335cdddddd8036c0fc30f8aa6fb2170c7bcaf101fcf384a6dca6aa8dbde/top2vec-1.0.20-py3-none-any.whl\n",
            "Requirement already satisfied: pynndescent>=0.4 in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (0.5.1)\n",
            "Collecting hdbscan\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/2f/2423d844072f007a74214c1adc46260e45f034bb1679ccadfbb8a601f647/hdbscan-0.8.26.tar.gz (4.7MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7MB 10.7MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting joblib<1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/c9/f58220ac44a1592f79a343caba12f6837f9e0c04c196176a3d66338e1ea8/joblib-0.17.0-py3-none-any.whl (301kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 42.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (1.1.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (3.6.0)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (0.5.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (1.5.0)\n",
            "Collecting tensorflow-text; extra == \"sentence_encoders\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/86/22ad798f94d564c3e423758b60ddd3689e83ad629b3f31ff2ae45a6e3eed/tensorflow_text-2.4.3-cp36-cp36m-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 43.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow; extra == \"sentence_encoders\" in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-hub; extra == \"sentence_encoders\" in /usr/local/lib/python3.6/dist-packages (from top2vec[sentence_encoders]) (0.11.0)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from pynndescent>=0.4->top2vec[sentence_encoders]) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from pynndescent>=0.4->top2vec[sentence_encoders]) (0.22.2.post1)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.6/dist-packages (from pynndescent>=0.4->top2vec[sentence_encoders]) (0.51.2)\n",
            "Requirement already satisfied: llvmlite>=0.30 in /usr/local/lib/python3.6/dist-packages (from pynndescent>=0.4->top2vec[sentence_encoders]) (0.34.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hdbscan->top2vec[sentence_encoders]) (1.15.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.6/dist-packages (from hdbscan->top2vec[sentence_encoders]) (0.29.21)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->top2vec[sentence_encoders]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->top2vec[sentence_encoders]) (4.1.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->top2vec[sentence_encoders]) (7.0.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.12.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.12.4)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.10.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.36.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.51.2->pynndescent>=0.4->top2vec[sentence_encoders]) (51.3.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (4.7)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.4.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow; extra == \"sentence_encoders\"->top2vec[sentence_encoders]) (3.1.0)\n",
            "Building wheels for collected packages: hdbscan\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.26-cp36-cp36m-linux_x86_64.whl size=2301804 sha256=415f843a132cdd1098c95b772a018415b849566a59df7484dbb60e2abe6b96db\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/38/41/372f034d8abd271ef7787a681e0a47fc05d472683a7eb088ed\n",
            "Successfully built hdbscan\n",
            "Installing collected packages: joblib, hdbscan, tensorflow-text, top2vec\n",
            "  Found existing installation: joblib 1.0.0\n",
            "    Uninstalling joblib-1.0.0:\n",
            "      Successfully uninstalled joblib-1.0.0\n",
            "Successfully installed hdbscan-0.8.26 joblib-0.17.0 tensorflow-text-2.4.3 top2vec-1.0.20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlhMY9fwBA48"
      },
      "source": [
        "from top2vec import Top2Vec"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3p_5KBJBBA49",
        "outputId": "17101284-47e9-4888-ebf5-af03dc454206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic_model = Top2Vec(list(sentence_df.text),embedding_model='universal-sentence-encoder',speed=\"deep-learn\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-01 05:21:29,952 - top2vec - INFO - Pre-processing documents for training\n",
            "2021-02-01 05:21:30,312 - top2vec - INFO - Downloading universal-sentence-encoder model\n",
            "2021-02-01 05:21:47,081 - top2vec - INFO - Creating joint document/word embedding\n",
            "INFO:top2vec:Creating joint document/word embedding\n",
            "2021-02-01 05:21:48,557 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "INFO:top2vec:Creating lower dimension embedding of documents\n",
            "2021-02-01 05:22:27,947 - top2vec - INFO - Finding dense areas of documents\n",
            "INFO:top2vec:Finding dense areas of documents\n",
            "2021-02-01 05:22:28,192 - top2vec - INFO - Finding topics\n",
            "INFO:top2vec:Finding topics\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1PdaQo3BA49",
        "outputId": "1c920105-5d8a-4473-e9e4-1fb3a411b0c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic_model.get_num_topics()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAN3mDCpBA4-",
        "outputId": "48bc4699-8ced-4d88-ee92-54f55f8a9f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "topic_sizes, topic_nums = topic_model.get_topic_sizes()\n",
        "topic_sizes, topic_nums"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4748,  252]), array([0, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSbpax_0BA4-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}